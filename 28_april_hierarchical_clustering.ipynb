{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3be3a34-32b5-452f-800d-198113f0efaf",
   "metadata": {},
   "source": [
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1295b3-2500-46a4-965f-4706fc63d6cb",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50125e8-6a4c-4cd3-bdde-8380e30380aa",
   "metadata": {},
   "source": [
    "Hierarchical clustering is a clustering technique that groups similar objects into clusters based on their distance from each other. It is different from other clustering techniques in that it creates a hierarchy of clusters rather than a flat partitioning of the data. Hierarchical clustering can be divided into two types: agglomerative and divisive.\n",
    "\n",
    "* Agglomerative hierarchical clustering starts with each object as a separate cluster and then merges the closest pairs of clusters until all objects belong to a single cluster. \n",
    "\n",
    "* Divisive hierarchical clustering starts with all objects in a single cluster and then recursively splits the cluster into smaller clusters until each object is in its own cluster.\n",
    "\n",
    "Advantage:\n",
    "* The main advantage of hierarchical clustering is that it can reveal the underlying structure of your data and can be more interpretable than other clustering methods, as it produces a dendrogram that shows the relationships between clusters.\n",
    "\n",
    "Disadvantage :\n",
    "\n",
    "* Hierarchical clustering can be computationally expensive and may not scale well to large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eff698-3925-4f58-9a45-f73756fc7bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8915b-b138-426a-8643-32ccfe90f0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cd6aae5-af36-45e0-8b14-e20398a4de24",
   "metadata": {},
   "source": [
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea814b6-25af-4706-9997-de069f98750e",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fc127-93d3-43a6-b962-17f9f3378eb4",
   "metadata": {},
   "source": [
    "Hierarchical clustering has two main types of algorithms: agglomerative and divisive.\n",
    "\n",
    "* Agglomerative hierarchical clustering is a bottom-up approach that starts with each object as a separate cluster and then merges the closest pairs of clusters until all objects belong to a single cluster.\n",
    "\n",
    "* Divisive hierarchical clustering is a top-down approach that starts with all objects in a single cluster and then recursively splits the cluster into smaller clusters until each object is in its own cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b076a8e-a591-4b9a-b729-6f973b530264",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f49352-29ff-44a1-9079-57fa2e0ec4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "507cf072-9281-4bf1-bc30-2757ccdd97b8",
   "metadata": {},
   "source": [
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the\n",
    "common distance metrics used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9ad61-e257-4e55-a394-bda9cb10f7e4",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f709bdc-21bb-47a4-840d-af45b20a22db",
   "metadata": {},
   "source": [
    "The distance between two clusters in hierarchical clustering is determined by a distance metric. The most commonly used distance metrics are Euclidean distance and Manhattan distance. Euclidean distance is useful when the data is continuous and has a normal distribution, while Manhattan distance is useful when the data is categorical or binary.\n",
    "\n",
    "Other distance metrics that can be used in hierarchical clustering include:\n",
    "\n",
    "* Pearson correlation distance\n",
    "* Spearman correlation distance\n",
    "* Kendall correlation distance\n",
    "* Mahalanobis distance\n",
    "\n",
    "These are just a few examples of the distance metrics that can be used in hierarchical clustering. The choice of distance metric will depend on the specific problem being solved and the characteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502fa73f-98c6-42c8-9dbf-63b3b80cff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301fe0f-4796-4416-8577-206f510182fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494682b9-4d2d-4c3c-ac65-6b2a8d965d81",
   "metadata": {},
   "source": [
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some\n",
    "common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7288d-8615-4f61-aa95-b82a7dc6ba93",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324a787-69f2-4868-bcd0-82c31b0111f5",
   "metadata": {},
   "source": [
    "The optimal number of clusters in hierarchical clustering can be determined using several methods. Here are some common methods used for this purpose:\n",
    "\n",
    "* Dendrogram: A dendrogram is a tree-like diagram that shows the hierarchical relationship between objects. The optimal number of clusters can be determined by identifying the point on the dendrogram where the distance between clusters starts to increase rapidly.\n",
    "\n",
    "* Elbow method: The elbow method is a popular method for determining the optimal number of clusters. It works by plotting the relationship between the number of clusters and the within-cluster sum of squares (WCSS). The optimal number of clusters is where the WCSS starts to level off.\n",
    "\n",
    "* Silhouette method: The silhouette method is another popular method for determining the optimal number of clusters. It works by calculating the silhouette coefficient for each data point. The silhouette coefficient measures how similar a data point is to its own cluster compared to other clusters. The optimal number of clusters is where the average silhouette coefficient is maximized.\n",
    "\n",
    "These are just a few examples of common methods used for determining the optimal number of clusters in hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37777e30-bb6d-4cc1-b29b-bbf12e19ee45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e0546-60c2-44da-b843-4bc56c3a345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74e6e364-0d05-4130-8da3-4323b1863ca9",
   "metadata": {},
   "source": [
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aeb195-6042-41e3-9c36-834537e6f7c7",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1cbaf-49a9-4fa6-a172-7207da1764f7",
   "metadata": {},
   "source": [
    "A dendogram is a diagram that shows the hierarchical relationship between objects ,commonly created as an output from hierarchical clustering. Dendograms are also used in phylogenetics to visualize relatedness or dissimilarities between species, and in RNA sequencing to show clustering of samples by clustering of genes that are similarly expressed. The height of the vertical lines and the range of the(dis)similarity axis give visual clues about the strength of the clustering.\n",
    "\n",
    "In hierarchical clustering, dendograms are used to divide into multiple clusters as soon as a cluster is created. The distance of split or merge (called height) is shown on the y-axis of the dendogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65df890-c34c-41e3-bf97-0dbc1a530327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd80a24-4d22-42cf-8543-dd146fc21268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eaf62c5-e222-4780-83a2-b4cedd096eb5",
   "metadata": {},
   "source": [
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8949c-be4b-4ed6-89d7-d12f065f96e0",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe60689-9b31-4db3-a808-bf52cb5db7cc",
   "metadata": {},
   "source": [
    "Yes, hierarchical clustering can be used for both numerical and categorical data. However, the choice of distance metric may depend on the type of data being clustered. For numeric data, Euclidean distance is commonly used, while for categorical data, Manhattan distance or other distance metrics may be used ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed11431-39dd-4ae5-b3b4-27ac2790e23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cc9f2-8801-4378-bfd2-c9e040955597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5209c270-4029-4f79-94db-399143bdfe30",
   "metadata": {},
   "source": [
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e723ad-972c-4ec0-bfc3-0bdb276b1696",
   "metadata": {},
   "source": [
    "Solution :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e065738-73e5-4fbe-b7ea-779f6a705a19",
   "metadata": {},
   "source": [
    "Hierarchical clustering can be used to identify outliers or anomalies in your data. One way to do this is by using the distance between the data points and the cluster centers. Points that are far away from the cluster centers are considered outliers ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ddd2f-55c2-40d1-8280-181ba0cc1240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce91dc70-d905-42d7-96c8-cf708c8f0624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
